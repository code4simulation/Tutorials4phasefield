import numpy as np
import sys
import os

class MaterialProperties:
    """
    Generic Material Properties container with methods for
    Wilson-Frenkel growth and CNT nucleation driving force.
    Initialized with values from configuration.
    """
    def __init__(self, 
                 Tm: float = 1687.0, 
                 Hf: float = 50.21e3, # J/mol
                 Vm: float = 12.0e-6, # m^3/mol
                 sigma: float = 0.32, 
                 V0: float = 3000.0, 
                 Qdiff_eV: float = 0.5, 
                 I0: float = 1e39):
        
        self.Tm = Tm
        self.Hf = Hf
        self.Vm = Vm
        self.sigma = sigma
        self.V0 = V0
        self.Qdiff_eV = Qdiff_eV
        self.I0 = I0
        
        # Constants
        self.kB = 1.380649e-23
        self.R = 8.314
        self.eV_to_J = 1.60218e-19

    def get_driving_force(self, T: float) -> float:
        """
        Calculates Gibbs Free Energy Change per UNIT VOLUME (J/m^3).
        dGv = (L * dT) / (Tm * Vm) approximation.
        """
        if T >= self.Tm:
            return 0.0
        
        # dG_molar [J/mol]
        dG_molar = self.Hf * (self.Tm - T) / self.Tm
        
        # dG_volume [J/m^3]
        return dG_molar / self.Vm

    def get_physical_velocity(self, T: float) -> float:
        """
        Calculates theoretical Wilson-Frenkel growth velocity (m/s).
        """
        if T >= self.Tm:
            return 0.0
            
        Q_J = self.Qdiff_eV * self.eV_to_J
        dG_molar = self.Hf * (self.Tm - T) / self.Tm
        
        kinetic_term = np.exp(-Q_J / (self.kB * T))
        thermo_term = 1.0 - np.exp(-dG_molar / (self.R * T))
        
        return self.V0 * kinetic_term * thermo_term

class DimensionlessSystem:
    def __init__(self, dx_real_meters: float, V_ref_meters_per_sec: float, sigma: float):
        self.l0 = dx_real_meters
        self.E0 = sigma / self.l0
        if V_ref_meters_per_sec < 1e-12:
            V_ref_meters_per_sec = 1e-12
        self.t0 = self.l0 / V_ref_meters_per_sec

    def to_sim_energy(self, J_per_m3: float) -> float:
        return J_per_m3 / self.E0

    def to_real_time(self, t_sim: float) -> float:
        return t_sim * self.t0
        
    def to_real_length(self, x_sim: float) -> float:
        return x_sim * self.l0

def determine_required_epsilon(T_val, scale, mat, safety_factor=2.0):
    """
    Calculates the minimum required penalty coefficient epsilon based on physical driving force.
    Condition: Penalty Force > Max Driving Force at interface.
    
    F_drive_max approx 1.875 * dG_sim (at phi=0.5)
    F_penalty approx 0.25 * epsilon (at collision phi=0.5, 0.5)
    
    Required epsilon > 7.5 * dG_sim
    """
    dG_real = mat.get_driving_force(T_val)
    dG_sim = scale.to_sim_energy(dG_real)
    
    if dG_sim < 0: return 5.0 # Min safe value for stable phases
    
    epsilon_req = 7.5 * dG_sim
    epsilon_final = epsilon_req * safety_factor
    
    print(f"[AUTO-PENALTY] T={T_val}K, dG_sim={dG_sim:.4f} -> Req Eps={epsilon_req:.2f}, Final Eps={epsilon_final:.2f} (Safety={safety_factor})")
    return epsilon_final

def load_packed_vtk(file_path):
    """
    Helper function to load a Custom VTK file generated by the simulation.
    Format:
      - Header
      - Any number of SCALARS fields
    
    Args:
        file_path (str): Path to the .vtk file.
        
    Returns:
        dict: {
            'arrays': { 'Name': np.ndarray, ... },
            'nx': int,
            'ny': int
        }
    """
    import numpy as np
    import re
    
    with open(file_path, 'rb') as f:
        # 1. Read Header until POINT_DATA
        header_lines = []
        nx, ny = 0, 0
        point_data_count = 0
        
        while True:
            line_bytes = f.readline()
            if not line_bytes: break
            line = line_bytes.decode('utf-8', errors='ignore').strip()
            header_lines.append(line)
            
            if line.startswith("DIMENSIONS"):
                parts = line.split()
                # VTK Dimensions: DIMENSIONS Ny Nx 1
                ny = int(parts[1])
                nx = int(parts[2])
            
            if line.startswith("POINT_DATA"):
                point_data_count = int(line.split()[1])
                break
                
        if nx == 0 or ny == 0:
            raise ValueError(f"Failed to parse dimensions from {file_path}")
            
        # 2. Read Arrays Loop
        arrays = {}
        
        while True:
            # Look for SCALARS or VECTORS line
            # We skip empty lines or whitespace logic manually if needed, but readline usually suffices if format is strict
            # C++ code puts newlines between arrays
            
            # Read line, expecting SCALARS Name type num_comp
            line_bytes = f.readline()
            if not line_bytes: break # End of file
            line = line_bytes.decode('utf-8', errors='ignore').strip()
            if not line: continue
            
            if line.startswith("SCALARS"):
                # SCALARS Name float 1
                parts = line.split()
                name = parts[1]
                
                # Consume LOOKUP_TABLE default
                lt_line = f.readline().decode('utf-8', errors='ignore').strip()
                
                # Read Data
                # Assuming float (4 bytes)
                count = nx * ny
                data_bytes = f.read(count * 4)
                if len(data_bytes) != count * 4:
                    print(f"[WARN] Truncated data for {name}")
                    break
                    
                arr = np.frombuffer(data_bytes, dtype='>f4').astype(np.float64)
                arrays[name] = arr.reshape(nx, ny) # Row-Major from C++
                
            elif line.startswith("VECTORS"):
                 # Legacy support or if mixed
                 parts = line.split()
                 name = parts[1]
                 count = nx * ny
                 data_bytes = f.read(count * 3 * 4)
                 arr = np.frombuffer(data_bytes, dtype='>f4').astype(np.float64)
                 arrays[name] = arr.reshape(nx, ny, 3)
            
    return {
        'arrays': arrays,
        'nx': nx,
        'ny': ny
    }

def resume_from_vtk(vtk_path, config):
    """
    Parses a packed VTK file to reconstruct the simulation state (Phi Grid).
    Returns (phi_grid, step_number)
    
    phi_grid shape: (max_grains, Nx, Ny)
    """
    import os
    import re
    
    print(f"[*] Resuming from VTK: {vtk_path}")
    if not os.path.exists(vtk_path):
        print(f"[ERROR] Resume file not found: {vtk_path}")
        return None, 0
        
    try:
        # 1. Parse Step Number from filename (output_001234.vtk)
        basename = os.path.basename(vtk_path)
        match = re.search(r'output_(\d+)\.vtk', basename)
        if match:
             start_step = int(match.group(1))
        else:
             print("[WARN] Could not parse step number from filename. Assumiang step 0.")
             start_step = 0
             
        # 2. Load VTK Data
        data = load_packed_vtk(vtk_path)
        arrays = data['arrays']
        nx_file = data['nx']
        ny_file = data['ny']
        
        # 3. Validate Dimensions
        if nx_file != config['Nx'] or ny_file != config['Ny']:
            print(f"[ERROR] Mismatch in dimensions. File: ({nx_file}, {ny_file}), Config: ({config['Nx']}, {config['Ny']})")
            return None, 0
            
        # 4. Reconstruct Phi Grid
        max_grains = config['max_grains']
        phi_grid = np.zeros((max_grains, config['Nx'], config['Ny']), dtype=np.float64)
        
        count_loaded = 0
        for name, arr in arrays.items():
            if name.startswith("Phi_"):
                try:
                    gid = int(name.split('_')[1])
                    if gid < max_grains:
                        phi_grid[gid, :, :] = arr
                        count_loaded += 1
                except ValueError:
                    continue
                    
        print(f"[+] Loaded {count_loaded} active grains from step {start_step}.")
        return phi_grid, start_step

    except Exception as e:
        print(f"[ERROR] Failed to resume from VTK: {e}")
        return None, 0
